{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "#### Run this script to proprocess all the data that will be coming in from one, many, or all of the following sources:\n",
    "1. **MonkeyLogic:** (.bhv2 | .h5) behavior data *[500 or 1000Hz]*\n",
    "  > * Photodiode data\n",
    "  > * White Matter Camera Sync analog data (if applicable)\n",
    "  > * White Matter Camera Save analog data (if applicable)\n",
    "2. **SpikeGLX:** (.meta & .bin) duplicates of analog data *[20000-30000Hz]*\n",
    "  > * Photodiode data (split from ML)\n",
    "  > * White Matter Camera Sync analog data (if applicable)\n",
    "  > * White Matter Camera Save analog data (if applicable)\n",
    "3. **WhiteMatter:** (.mp4 | .avi) video files *[60-120 fps]*\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Files\n",
    "`FileContainer` will hold the relevant files listed above. <br>\n",
    "* Specify `ROOT_DIR` to set the directory when prompted to select the files.\n",
    "* `WARNING` printed if dates and monkeys not aligned across files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Select behavior file\n",
      "Behavior file selected: /Users/rahimhashim/Library/CloudStorage/GoogleDrive-rh2898@columbia.edu/.shortcut-targets-by-id/1LV5133wM_1EY8V6-UnKI9D7kmJwfyE52/data_Probabilistic_Reward_Airpuff_Choice/230928_Bear_choice.h5\n",
      "  MonkeyLogic Date: 230928\n",
      "  MonkeyLogic Monkey: bear\n",
      "Select directory containing White Matter video files\n",
      "Video files directory selected: /Users/rahimhashim/Library/CloudStorage/GoogleDrive-rh2898@columbia.edu/.shortcut-targets-by-id/1weRx7ojG3amil91WgRMeTUVxse__Rsyt/rhAirpuff/8. Probabilistic_Reward_Airpuff_Choice/videos/230928_Bear\n",
      "  White Matter Video Date: 230928\n",
      "  White Matter Video Monkey: bear\n",
      "Select directory containing SpikeGLX files\n",
      "SpikeGLX files directory selected: /Users/rahimhashim/Library/CloudStorage/GoogleDrive-rh2898@columbia.edu/.shortcut-targets-by-id/1LV5133wM_1EY8V6-UnKI9D7kmJwfyE52/data_Probabilistic_Reward_Airpuff_Choice/bear_20230928_g0\n",
      "  SpikeGLX Date: 20230928\n",
      "  SpikeGLX Monkey: bear\n",
      "\n",
      "WARNING: dates do not match\n",
      "  MonkeyLogic: 230928\n",
      "  SpikeGLX: 20230928\n",
      "WARNING: dates do not match\n",
      "  White Matter: 230928\n",
      "  SpikeGLX: 20230928\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "# Custom classes\n",
    "from classes.FileContainer import FileContainer\n",
    "from classes.SpikeGLX import SpikeGLX\n",
    "# Custom functions\n",
    "from spike_glx import read_SGLX\n",
    "\n",
    "# pandas options\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "ROOT_DIR = '/Users/rahimhashim/My Drive/Columbia/Salzman/Monkey-Training/tasks/rhAirpuff'\n",
    "file_container_obj = FileContainer(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Convert MonkeyLogic File to Pandas\n",
    "In order to run the behavior files through the preprocessing pipeline, we'll need to convert the MonkeyLogic file (either `.bhv2` or `.h5`) into a Session object which contains the following relevant attributes:\n",
    "> * `session_obj.df`: pandas DataFrame with columns:\n",
    ">   * `'photodiode'`: photodiode signal\n",
    ">   * `'Gen2'`: WM sync signal\n",
    ">   * `'Gen3'`: WM save signal\n",
    "> * `'session_obj.video_path'`: directory of WM videos\n",
    "> * `session_obj.monkey`: monkey name\n",
    "> * `session_obj.date`: date of session (<YYMMDD>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing .h5 file...\n",
      "Total number of trials: 825\n",
      "  Choice task detected.\n",
      "Parsing session data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "162873c18d884630afd58730c7befd88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/825 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Complete.\n",
      "    Correct trials: 400\n",
      "    Errored trials: 425\n",
      "    Session Length:  01:21:42\n",
      "Creating Session Objects...\n",
      "Lick threshold: 3.77 mV\n",
      "  Min Values (X,Y): (-98.172,-33.237)\n",
      "  Max Values (X,Y): (108.878,132.294)\n",
      "  Reward Mag: 1.0\n",
      "    Reward Drops: 12.0\n",
      "    Reward Frequency: 1.0\n",
      "    Reward Length: 175.0\n",
      "  Reward Mag: 0.5\n",
      "    Reward Drops: 5.0\n",
      "    Reward Frequency: 1.0\n",
      "    Reward Length: 150.0\n",
      "  Reward Mag: 0.0\n",
      "    Reward Drops: 0.0\n",
      "    Reward Frequency: 0.0\n",
      "    Reward Length: 0.0\n",
      "  Airpuff Mag: 1.0\n",
      "    Airpuff Magnitude: 1.0\n",
      "    Airpuff Frequency: 1.0\n",
      "  Airpuff Mag: 0.5\n",
      "    Airpuff Magnitude: 0.5\n",
      "    Airpuff Frequency: 1.0\n",
      "  Airpuff Mag: 0.0\n",
      "    Airpuff Magnitude: 0.0\n",
      "    Airpuff Frequency: 0.0\n",
      "Adding additional fields to session_df DataFrame...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahimhashim/Desktop/Monkey-Emotions/config/add_fields.py:335: RuntimeWarning: Mean of empty slice\n",
      "  lick_avg = np.nanmean(lick_in_window)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  20 new fields added.\n"
     ]
    }
   ],
   "source": [
    "session_obj, error_dict, behavioral_code_dict = file_container_obj.ml_to_pd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "## Process SpikeGLX\n",
    "Once you have `session_obj` with a `df` attribute referencing a `pd.DataFrame`, it will check for required fields `photodiode`, `cam_sync`, and `cam_save`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pickled spikeglx_obj: /Users/rahimhashim/Desktop/Monkey-Emotions/spikeglx_obj_bear_230928.pkl\n"
     ]
    }
   ],
   "source": [
    "from spike_glx.load_SGLX import load_sglx\n",
    "\n",
    "# Manually assign the signal channel numbers\n",
    "# from how you set them up on the NI PXIe-6341 board\n",
    "signal_dict = {\n",
    "  0: 'cam_sync',\n",
    "  1: 'cam_save',\n",
    "  2: 'lick',\n",
    "  3: 'photodiode',\n",
    "  4: 'empty'\n",
    "}\n",
    "\n",
    "# Manually assign the time epochs you care about\n",
    "# which have to exist as rows in session_df\n",
    "epochs = ['Start Trial', 'Fixation On', 'CS On',\t\n",
    "          'Trace Start', 'Outcome Start', 'End Trial']\n",
    "# Load the spikeglx object\n",
    "spikeglx_obj = load_sglx(session_obj.df, \n",
    "                         session_obj, \n",
    "                         file_container_obj.spikeglx_dir_path, \n",
    "                         signal_dict, \n",
    "                         epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Process White Matter Videos\n",
    "\n",
    "After generating a `SpikeGLX` object, you can segment all the White Matter videos by trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from video.wm_videos import parse_wm_videos\n",
    "\n",
    "kwargs = {'spikeglx_obj': spikeglx_obj, \n",
    "          'session_obj': session_obj, \n",
    "          'trial_start': 0,\n",
    "          'trial_end': len(session_obj.df),\n",
    "          'epoch_start': 'Trace Start', \n",
    "          'epoch_end': 'Outcome Start', \n",
    "          'thread_flag': True}\n",
    "\n",
    "parse_wm_videos(**kwargs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facial-recognition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
